{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90824ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c71ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks = True)\n",
    "cap=cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b04acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "LEFT_IRIS = 468\n",
    "RIGHT_IRIS = 473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4538f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_w, screen_h = pyautogui.size()\n",
    "last_click_time = 0\n",
    "fixation_start_time = None\n",
    "last_gaze_pos = None\n",
    "fixation_threshold = 0.03  \n",
    "fixation_duration = 1.2\n",
    "zoom_trigger_time = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "960a0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(landmarks, eye_points):\n",
    "    p1=landmarks[eye_points[1]]\n",
    "    p2=landmarks[eye_points[2]]\n",
    "    p3=landmarks[eye_points[3]]\n",
    "    p4=landmarks[eye_points[4]]\n",
    "\n",
    "    vertical = ((p2.y - p4.y) ** 2 + (p2.x - p4.x) ** 2) ** 0.5\n",
    "    horizontal = ((p1.y - p3.y) ** 2 + (p1.x - p3.x) ** 2) ** 0.5\n",
    "\n",
    "    return vertical/horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d338a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fixated(current_pos, previous_pos, threshold=fixation_threshold):\n",
    "    if previous_pos is None:\n",
    "        return False\n",
    "    dist = np.linalg.norm(np.array(current_pos) - np.array(previous_pos))\n",
    "    return dist < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6096da",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m ret, frame = cap.read()\n\u001b[32m      3\u001b[39m frame = cv2.flip(frame, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m rgb = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m results = face_mesh.process(rgb)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m results.multi_face_landmarks:\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        mesh = results.multi_face_landmarks[0]\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        # مختصات مردمک‌ها\n",
    "        left_iris = mesh.landmark[LEFT_IRIS]\n",
    "        right_iris = mesh.landmark[RIGHT_IRIS]\n",
    "        qqqq\n",
    "        gaze_x = (left_iris.x + right_iris.x) / 2\n",
    "        gaze_y = (left_iris.y + right_iris.y) / 2\n",
    "\n",
    "        # تشخیص نگاه ثابت (fixation)\n",
    "        if is_fixated((gaze_x, gaze_y), last_gaze_pos):\n",
    "            if fixation_start_time is None:\n",
    "                fixation_start_time = time.time()\n",
    "            elapsed = time.time() - fixation_start_time\n",
    "\n",
    "            # حرکت ماوس فقط در صورت نگاه ثابت\n",
    "            if elapsed > fixation_duration:\n",
    "                screen_x = int(gaze_x * screen_w)\n",
    "                screen_y = int(gaze_y * screen_h)\n",
    "                pyautogui.moveTo(screen_x, screen_y, duration=0.1)\n",
    "\n",
    "                # اگر به مرکز نگاه کند و زیاد بماند، زوم کند\n",
    "                center_x = 0.5\n",
    "                center_y = 0.5\n",
    "                if abs(gaze_x - center_x) < 0.05 and abs(gaze_y - center_y) < 0.05:\n",
    "                    if elapsed > zoom_trigger_time:\n",
    "                        pyautogui.scroll(500)  # اسکرول به بالا (زوم)\n",
    "                        time.sleep(1)\n",
    "        else:\n",
    "            fixation_start_time = None\n",
    "\n",
    "        last_gaze_pos = (gaze_x, gaze_y)\n",
    "\n",
    "        # تشخیص پلک زدن\n",
    "        left_ear = eye_aspect_ratio(mesh.landmark, LEFT_EYE)\n",
    "        right_ear = eye_aspect_ratio(mesh.landmark, RIGHT_EYE)\n",
    "\n",
    "        blink_thresh = 0.22\n",
    "        left_closed = left_ear < blink_thresh\n",
    "        right_closed = right_ear < blink_thresh\n",
    "\n",
    "        if left_closed and right_closed:\n",
    "            now = time.time()\n",
    "            if now - last_click_time > 1:\n",
    "                pyautogui.doubleClick()\n",
    "                last_click_time = now\n",
    "            time.sleep(0.6)\n",
    "\n",
    "        elif left_closed and not right_closed:\n",
    "            pyautogui.click(button='left')\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        elif right_closed and not left_closed:\n",
    "            pyautogui.click(button='right')\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    cv2.imshow(\"eye_control\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
